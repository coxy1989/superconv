{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append('..')\n",
    "import modules.callbacks as cbs\n",
    "import modules.model as mdl\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "RESULTS_DIR = '../results/experiment_mnist_1cycle_12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "118/118 [==============================] - 49s 418ms/step - loss: 0.6371 - acc: 0.8244 - val_loss: 0.1107 - val_acc: 0.9660\n",
      "Epoch 2/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0915 - acc: 0.9727 - val_loss: 0.0563 - val_acc: 0.9813\n",
      "Epoch 3/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0561 - acc: 0.9829 - val_loss: 0.0491 - val_acc: 0.9833\n",
      "Epoch 4/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0411 - acc: 0.9876 - val_loss: 0.0448 - val_acc: 0.9857\n",
      "Epoch 5/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0318 - acc: 0.9901 - val_loss: 0.0441 - val_acc: 0.9868\n",
      "Epoch 6/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0261 - acc: 0.9919 - val_loss: 0.0412 - val_acc: 0.9866\n",
      "Epoch 7/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0193 - acc: 0.9942 - val_loss: 0.0332 - val_acc: 0.9895\n",
      "Epoch 8/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0148 - acc: 0.9957 - val_loss: 0.0326 - val_acc: 0.9892\n",
      "Epoch 9/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0107 - acc: 0.9971 - val_loss: 0.0342 - val_acc: 0.9893\n",
      "Epoch 10/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0285 - val_acc: 0.9905\n",
      "Epoch 11/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0064 - acc: 0.9988 - val_loss: 0.0335 - val_acc: 0.9895\n",
      "Epoch 12/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0055 - acc: 0.9990 - val_loss: 0.0289 - val_acc: 0.9906\n",
      "Epoch 1/12\n",
      "118/118 [==============================] - 32s 275ms/step - loss: 0.6766 - acc: 0.8122 - val_loss: 0.1043 - val_acc: 0.9692\n",
      "Epoch 2/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0884 - acc: 0.9735 - val_loss: 0.0622 - val_acc: 0.9822\n",
      "Epoch 3/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0565 - acc: 0.9823 - val_loss: 0.0527 - val_acc: 0.9830\n",
      "Epoch 4/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0398 - acc: 0.9876 - val_loss: 0.0401 - val_acc: 0.9866\n",
      "Epoch 5/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0305 - acc: 0.9907 - val_loss: 0.0422 - val_acc: 0.9869\n",
      "Epoch 6/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0241 - acc: 0.9928 - val_loss: 0.0349 - val_acc: 0.9871\n",
      "Epoch 7/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0184 - acc: 0.9944 - val_loss: 0.0299 - val_acc: 0.9907\n",
      "Epoch 8/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0148 - acc: 0.9959 - val_loss: 0.0356 - val_acc: 0.9900\n",
      "Epoch 9/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0107 - acc: 0.9972 - val_loss: 0.0327 - val_acc: 0.9899\n",
      "Epoch 10/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0080 - acc: 0.9983 - val_loss: 0.0292 - val_acc: 0.9914\n",
      "Epoch 11/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0062 - acc: 0.9990 - val_loss: 0.0312 - val_acc: 0.9911\n",
      "Epoch 12/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0053 - acc: 0.9992 - val_loss: 0.0311 - val_acc: 0.9908\n",
      "Epoch 1/12\n",
      "118/118 [==============================] - 33s 277ms/step - loss: 0.6705 - acc: 0.8056 - val_loss: 0.1114 - val_acc: 0.9665\n",
      "Epoch 2/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0882 - acc: 0.9732 - val_loss: 0.0651 - val_acc: 0.9800\n",
      "Epoch 3/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0560 - acc: 0.9826 - val_loss: 0.0490 - val_acc: 0.9844\n",
      "Epoch 4/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0409 - acc: 0.9871 - val_loss: 0.0406 - val_acc: 0.9862\n",
      "Epoch 5/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0307 - acc: 0.9907 - val_loss: 0.0420 - val_acc: 0.9872\n",
      "Epoch 6/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0249 - acc: 0.9925 - val_loss: 0.0356 - val_acc: 0.9888\n",
      "Epoch 7/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0187 - acc: 0.9944 - val_loss: 0.0341 - val_acc: 0.9894\n",
      "Epoch 8/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0141 - acc: 0.9960 - val_loss: 0.0321 - val_acc: 0.9891\n",
      "Epoch 9/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0112 - acc: 0.9970 - val_loss: 0.0334 - val_acc: 0.9893\n",
      "Epoch 10/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0076 - acc: 0.9984 - val_loss: 0.0313 - val_acc: 0.9899\n",
      "Epoch 11/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0061 - acc: 0.9990 - val_loss: 0.0278 - val_acc: 0.9905\n",
      "Epoch 12/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0323 - val_acc: 0.9901\n",
      "Epoch 1/12\n",
      "118/118 [==============================] - 30s 252ms/step - loss: 0.7204 - acc: 0.7889 - val_loss: 0.1128 - val_acc: 0.9646\n",
      "Epoch 2/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0868 - acc: 0.9734 - val_loss: 0.0615 - val_acc: 0.9798\n",
      "Epoch 3/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0555 - acc: 0.9827 - val_loss: 0.0488 - val_acc: 0.9852\n",
      "Epoch 4/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0412 - acc: 0.9873 - val_loss: 0.0414 - val_acc: 0.9862\n",
      "Epoch 5/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0306 - acc: 0.9904 - val_loss: 0.0382 - val_acc: 0.9878\n",
      "Epoch 6/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0245 - acc: 0.9923 - val_loss: 0.0365 - val_acc: 0.9885\n",
      "Epoch 7/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0183 - acc: 0.9946 - val_loss: 0.0341 - val_acc: 0.9887\n",
      "Epoch 8/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0148 - acc: 0.9955 - val_loss: 0.0313 - val_acc: 0.9897\n",
      "Epoch 9/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0104 - acc: 0.9971 - val_loss: 0.0310 - val_acc: 0.9901\n",
      "Epoch 10/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0077 - acc: 0.9984 - val_loss: 0.0284 - val_acc: 0.9905\n",
      "Epoch 11/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0060 - acc: 0.9990 - val_loss: 0.0299 - val_acc: 0.9907\n",
      "Epoch 12/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0047 - acc: 0.9992 - val_loss: 0.0307 - val_acc: 0.9908\n",
      "Epoch 1/12\n",
      "118/118 [==============================] - 31s 261ms/step - loss: 0.6677 - acc: 0.8021 - val_loss: 0.1239 - val_acc: 0.9618\n",
      "Epoch 2/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0973 - acc: 0.9704 - val_loss: 0.0661 - val_acc: 0.9793\n",
      "Epoch 3/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0604 - acc: 0.9815 - val_loss: 0.0491 - val_acc: 0.9840\n",
      "Epoch 4/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0430 - acc: 0.9866 - val_loss: 0.0409 - val_acc: 0.9875\n",
      "Epoch 5/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0329 - acc: 0.9897 - val_loss: 0.0366 - val_acc: 0.9888\n",
      "Epoch 6/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0236 - acc: 0.9929 - val_loss: 0.0360 - val_acc: 0.9889\n",
      "Epoch 7/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0193 - acc: 0.9942 - val_loss: 0.0356 - val_acc: 0.9894\n",
      "Epoch 8/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0146 - acc: 0.9959 - val_loss: 0.0331 - val_acc: 0.9892\n",
      "Epoch 9/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0109 - acc: 0.9970 - val_loss: 0.0309 - val_acc: 0.9894\n",
      "Epoch 10/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0083 - acc: 0.9980 - val_loss: 0.0324 - val_acc: 0.9902\n",
      "Epoch 11/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0060 - acc: 0.9990 - val_loss: 0.0306 - val_acc: 0.9909\n",
      "Epoch 12/12\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.0050 - acc: 0.9993 - val_loss: 0.0324 - val_acc: 0.9903\n"
     ]
    }
   ],
   "source": [
    "def run():\n",
    "    mean_x = x_train.mean(axis=0)\n",
    "    train_xs, train_ys = mdl.gen_mnist_iterator(x_train - mean_x, y_train, 512).get_next()\n",
    "    test_xs, test_ys = mdl.gen_mnist_iterator(x_test - mean_x, y_test, 512).get_next()\n",
    "    model = mdl.gen_mnist_model()\n",
    "    opt = tf.keras.optimizers.SGD(0.01, decay=5e-4)\n",
    "    train_steps = math.ceil(x_train.shape[0] / 512)\n",
    "    test_steps = math.ceil(x_test.shape[0] / 512)\n",
    "    cb = cbs.OneCycleSchedulerCallback(cyc_iterations= 2 * 5 * math.ceil(60000 / 512) + 1,\n",
    "                                       ramp_iterations= 2 * math.ceil(60000 / 512),\n",
    "                                       min_lr=0.01,\n",
    "                                       max_lr=0.1,\n",
    "                                       min_mom=0.8,\n",
    "                                       max_mom=0.95)\n",
    "    model.compile(opt, \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model.fit(train_xs,\n",
    "                     train_ys,\n",
    "                     epochs=12,\n",
    "                     steps_per_epoch=train_steps,\n",
    "                     callbacks=[cb],\n",
    "                     validation_data=(test_xs, test_ys),\n",
    "                     validation_steps=test_steps)\n",
    "\n",
    "for idx in range(1, 6):\n",
    "    hx = run()\n",
    "    df = pd.DataFrame(hx.history)\n",
    "    df.to_csv(f'{RESULTS_DIR}/{idx}.csv', index=False)\n",
    "    tf.keras.backend.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
